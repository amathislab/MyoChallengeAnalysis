{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate plots for figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pickle\n",
    "import sklearn\n",
    "from helpers import average_by_timestep, measure_tangling\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.cm import get_cmap\n",
    "from definitions import ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Baoding-SV and Baoding-LV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baoding_sv_df = pd.read_hdf(os.path.join(ROOT_DIR, \"data\", \"datasets\", \"baoding_sv.h5\"))\n",
    "baoding_lv_df = pd.read_hdf(os.path.join(ROOT_DIR, \"data\", \"datasets\", \"baoding_lv.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the PCA of each layer to project to a common subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 25\n",
    "layer_names = [\"observation\", \"lstm_state_1\", \"lstm_out\", \"layer_1_out\", \"layer_2_out\", \"action\"]\n",
    "readable_layer_names = [\"Observation\", \"LSTM state\", \"LSTM out\", \"Layer 1 out\", \"Layer 2 out\", \"Action\"]\n",
    "\n",
    "pca = PCA(n_components=n_comp)\n",
    "\n",
    "for layer in layer_names:\n",
    "    print(\"Layer: \", layer)\n",
    "    data = np.array(baoding_sv_df[layer].to_list())\n",
    "    embeddings = pca.fit_transform(data)\n",
    "    baoding_sv_df[layer + \"_pc\"] = list(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the average trajectory of the first 3 components of the pca of each layer (not part of the figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_step = 0\n",
    "df_trunc = baoding_sv_df[baoding_sv_df.step > first_step]\n",
    "for layer in layer_names:\n",
    "    data = np.array(df_trunc[layer + \"_pc\"].to_list())\n",
    "    umap_cw = data[df_trunc.task == \"cw\"]\n",
    "    umap_ccw = data[df_trunc.task == \"ccw\"]\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"Reds\"]\n",
    "    color_list = [cmap(i) for i in np.linspace(0.5, 1, len(df_trunc.step[df_trunc.task == \"cw\"].unique()))]    \n",
    "    colors = [color_list[idx] for idx in (df_trunc.step[df_trunc.task == \"cw\"] - first_step - 1)]\n",
    "    mean_traj = average_by_timestep(umap_cw[:, :3], df_trunc.step[df_trunc.task == \"cw\"])\n",
    "    ax.scatter(mean_traj[:, 0], mean_traj[:, 1], mean_traj[:, 2], c=color_list, label=\"Clockwise\")\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"Blues\"]\n",
    "    color_list = [cmap(i) for i in np.linspace(0.5, 1, len(df_trunc.step[df_trunc.task == \"ccw\"].unique()))]    \n",
    "    colors = [color_list[idx] for idx in (df_trunc.step[df_trunc.task == \"ccw\"] - first_step - 1)]\n",
    "    mean_traj = average_by_timestep(umap_ccw[:, :3], df_trunc.step[df_trunc.task == \"ccw\"])\n",
    "    ax.scatter(mean_traj[:, 0], mean_traj[:, 1], mean_traj[:, 2], c=color_list, label=\"Counter-clockwise\")\n",
    "    ax.set_title(layer)\n",
    "    ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.set_xlabel(\"\\nPC 1\")\n",
    "    ax.set_ylabel(\"\\nPC 2\")\n",
    "    ax.set_zlabel(\"\\nPC 3\")\n",
    "    ax.set_box_aspect(aspect=None, zoom=0.75)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 3d projection with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph per layer with UMAP\n",
    "for layer in layer_names:\n",
    "    print(\"Layer\", layer)\n",
    "    out_dir = os.path.join(ROOT_DIR, \"data\", \"embeddings\")\n",
    "    \n",
    "    with open(os.path.join(out_dir, f\"new_umap_embeddings_ccw_{layer}.pkl\"), \"rb\") as file:\n",
    "        umap_ccw = pickle.load(file)\n",
    "    with open(os.path.join(out_dir, f\"new_umap_embeddings_cw_{layer}.pkl\"), \"rb\") as file:\n",
    "        umap_cw = pickle.load(file)\n",
    "        \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "    \n",
    "    cmap = matplotlib.colormaps[\"Reds\"]\n",
    "    color_list = [cmap(i) for i in np.linspace(0.3, 1, len(df_trunc.step[df_trunc.task == \"cw\"].unique()))]    \n",
    "    colors = [color_list[idx] for idx in (df_trunc.step[df_trunc.task == \"cw\"] - first_step - 1)]\n",
    "    ax.scatter(umap_cw[:, 0], umap_cw[:, 1], umap_cw[:, 2], alpha=0.1, s=1, c=colors)\n",
    "    mean_traj = average_by_timestep(umap_cw[:, :3], df_trunc.step[df_trunc.task == \"cw\"])\n",
    "    \n",
    "    cmap = matplotlib.colormaps[\"Blues\"]\n",
    "    color_list = [cmap(i) for i in np.linspace(0.3, 1, len(df_trunc.step[df_trunc.task == \"ccw\"].unique()))]    \n",
    "    colors = [color_list[idx] for idx in (df_trunc.step[df_trunc.task == \"ccw\"] - first_step - 1)]\n",
    "    ax.scatter(umap_ccw[:, 0], umap_ccw[:, 1], umap_ccw[:, 2], alpha=0.1, s=1, c=colors)\n",
    "    mean_traj = average_by_timestep(umap_ccw[:, :3], df_trunc.step[df_trunc.task == \"ccw\"])\n",
    "\n",
    "    ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "\n",
    "    ax.set_xlabel(\"\\nUMAP 1\", fontsize=12)\n",
    "    ax.set_ylabel(\"\\nUMAP 2\", fontsize=12)\n",
    "    ax.set_zlabel(\"\\nUMAP 3\", fontsize=12)\n",
    "    ax.set_box_aspect(aspect=None, zoom=0.75)\n",
    "    ax.ticklabel_format(style=\"sci\", scilimits=(-2, 2))\n",
    "    ax.locator_params(axis='both', nbins=4)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "    plt.savefig(os.path.join(ROOT_DIR, \"data\", \"figures\", \"fig_6\", f\"umap_{layer}.png\"), format=\"png\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the tangling after projecting to an 8-dimensional space and generate the scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 8\n",
    "\n",
    "for layer in layer_names:\n",
    "    tangling_list = []\n",
    "    episode_pc_list = baoding_sv_df.groupby([\"episode\", \"task\"])[layer + \"_pc\"].agg(lambda x: np.vstack(x)[:, :num_components]).tolist()\n",
    "    for episode_pc in episode_pc_list:\n",
    "        tangling_list.append(measure_tangling(episode_pc))\n",
    "    print(layer, np.mean(tangling_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot tangling memory vs observation and memory vs action\n",
    "scatter_layer_names = [\"observation\", \"lstm_state_1\", \"action\"]\n",
    "tangling_dict = {}\n",
    "for layer in scatter_layer_names:\n",
    "    tangling_list = []\n",
    "    episode_pc_list = baoding_sv_df.groupby([\"episode\", \"task\"])[layer + \"_pc\"].agg(lambda x: np.vstack(x)[:, :num_components]).tolist()\n",
    "    for episode_pc in episode_pc_list:\n",
    "        tangling_list.append(measure_tangling(episode_pc))\n",
    "    tangling_dict[layer] = tangling_list\n",
    "\n",
    "# memory vs observation\n",
    "lim = (0, 8500)\n",
    "fig, ax = plt.subplots(figsize=(3.6, 3.6))\n",
    "ax.scatter(tangling_dict[\"observation\"], tangling_dict[\"lstm_state_1\"], s=0.5, color=\"dodgerblue\")\n",
    "ax.plot(lim, lim, color=\"red\")\n",
    "ax.set_xlabel(\"Observation space (86D)\", fontsize=13)\n",
    "ax.set_ylabel(\"Memory layer\\nrepresentation (256D)\", fontsize=13)\n",
    "ax.set_xlim(lim)\n",
    "ax.set_ylim(lim)\n",
    "ax.ticklabel_format(scilimits=(3, 3))\n",
    "out_name = \"scatter_tangling_memory_vs_observation.png\"\n",
    "fig.savefig(os.path.join(ROOT_DIR, \"data\", \"figures\", \"fig_6\", out_name), format=\"png\", dpi=800, bbox_inches=\"tight\")\n",
    "fig.show()\n",
    "\n",
    "# memory vs action\n",
    "lim = (0, 12500)\n",
    "fig, ax = plt.subplots(figsize=(3.6, 3.6))\n",
    "ax.scatter(tangling_dict[\"action\"], tangling_dict[\"lstm_state_1\"], s=0.5, color=\"dodgerblue\")\n",
    "ax.plot(lim, lim, color=\"red\")\n",
    "ax.set_xlabel(\"Action space (39D)\", fontsize=13)\n",
    "ax.set_ylabel(\"Memory layer\\nrepresentation (256D)\", fontsize=13)\n",
    "ax.set_xlim(lim)\n",
    "ax.set_ylim(lim)\n",
    "ax.ticklabel_format(scilimits=(3, 3))\n",
    "out_name = \"scatter_tangling_memory_vs_action.png\"\n",
    "fig.savefig(os.path.join(ROOT_DIR, \"data\", \"figures\", \"fig_6\", out_name), format=\"png\", dpi=800, bbox_inches=\"tight\")\n",
    "fig.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the linear readout of different variables from each layer of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First regress the continuous variables with linear regression (takes some minutes to run)\n",
    "results_list = []\n",
    "regression = sklearn.linear_model.LinearRegression()\n",
    "for target in [\"mass_1\", \"mass_2\", \"size_1\", \"size_2\", \"friction_0\", \"friction_1\", \"friction_2\", \"x_radius\", \"y_radius\"]:\n",
    "    for key in [\"observation\", \"lstm_state_0\", \"lstm_state_1\", \"lstm_out\", \"layer_1_out\", \"layer_2_out\", \"action\"]:\n",
    "        X = np.array(baoding_lv_df[key].to_list())\n",
    "        y = baoding_lv_df[target].to_numpy()\n",
    "        cv = sklearn.model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_score = sklearn.model_selection.cross_val_score(regression, X, y, cv=cv)\n",
    "        print(\"Key:\", key, \" target:\", target,  \"score:\", cv_score)\n",
    "        results_list.append({\"input\": key, \"target\": target, \"score\": cv_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then regress the categorical variable with logistic regression\n",
    "classification = sklearn.linear_model.LogisticRegression(max_iter=10_000)\n",
    "target = \"task\"\n",
    "for key in [\"observation\", \"lstm_state_0\", \"lstm_state_1\", \"lstm_out\", \"layer_1_out\", \"layer_2_out\", \"action\"]:\n",
    "    X = np.array(baoding_lv_df[key].to_list())\n",
    "    y = baoding_lv_df[target].to_numpy()\n",
    "    cv = sklearn.model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_score = sklearn.model_selection.cross_val_score(classification, X, y, cv=cv)\n",
    "    print(\"Key:\", key, \" target:\", target,  \"score:\", cv_score)\n",
    "    results_list.append({\"input\": key, \"target\": target, \"score\": cv_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally regress the continuous varibales with multiple values with linear regression\n",
    "regression = sklearn.linear_model.LinearRegression()\n",
    "for target in [\"hand_pos\", \"hand_vel\"]:\n",
    "    for key in [\"observation\", \"lstm_state_0\", \"lstm_state_1\", \"lstm_out\", \"layer_1_out\", \"layer_2_out\", \"action\"]:\n",
    "        X = np.array(baoding_lv_df[key].to_list())\n",
    "        y = np.array(baoding_lv_df[target].to_list())\n",
    "\n",
    "        cv = sklearn.model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_score = sklearn.model_selection.cross_val_score(regression, X, y, cv=cv)\n",
    "\n",
    "        print(\"Key:\", key, \" target:\", target,  \"score:\", cv_score)\n",
    "        results_list.append({\"input\": key, \"target\": target, \"score\": cv_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list_mean_sem = [{\n",
    "    \"input\": el[\"input\"],\n",
    "    \"target\": el[\"target\"],\n",
    "    \"score_mean\": np.mean(el[\"score\"]),\n",
    "    \"score_std\": np.std(el[\"score\"])\n",
    "    }\n",
    "    for el in results_list\n",
    "]\n",
    "results_df = pd.DataFrame(results_list_mean_sem)\n",
    "results_df.to_hdf(os.path.join(ROOT_DIR, \"data\", \"linear_encoding\", \"encoding_all_variables.h5\"), key=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_list = [\"observation\", \"lstm_state_1\", \"lstm_out\", \"layer_1_out\", \"layer_2_out\", \"action\"]\n",
    "layers_name_list = [\"Observation\", \"Memory\", \"LSTM output\", \"Layer 1\", \"Layer 2\", \"Action\"]\n",
    "targets_list = [\"mass_1\", \"mass_2\", \"size_1\", \"size_2\", \"friction_0\", \"friction_1\", \"friction_2\", \"x_radius\", \"y_radius\", \"task\", \"hand_pos\", \"hand_vel\"]\n",
    "targets_name_list = [\"Mass 1\", \"Mass 2\", \"Size 1\", \"Size 2\", \"Friction 0\", \"Friction 1\", \"Friction 2\", \"Radius x\", \"Radius y\", \"Task\", \"Joint pos\", \"Joint vel\"]\n",
    "\n",
    "# Create a pivot table to reshape the data\n",
    "pivot_data = results_df.pivot(index=\"target\", columns=\"input\", values=\"score_mean\").loc[targets_list]\n",
    "pivot_std = results_df.pivot(index=\"target\", columns=\"input\", values=\"score_std\").loc[targets_list]\n",
    "\n",
    "# Set the width of each bar\n",
    "bar_width = 0.15\n",
    "\n",
    "# Create an array of x values for the bars\n",
    "x = np.arange(len(targets_list))\n",
    "\n",
    "# Create a grouped barplot\n",
    "fig, ax = plt.subplots(figsize=(5, 3.5))\n",
    "cmap = get_cmap(\"coolwarm\")\n",
    "\n",
    "\n",
    "for i, layer in enumerate(layers_list):\n",
    "    ax.bar(x + i * bar_width, pivot_data[layer], bar_width, yerr=pivot_std[layer], label=layers_name_list[i], color=cmap((i) / (len(layers_list))), alpha=0.9)\n",
    "\n",
    "# Set x-axis labels and tick positions\n",
    "ax.set_xticks(x + (len(pivot_data.columns) / 2) * bar_width)\n",
    "ax.set_xticklabels(targets_name_list, rotation=45, ha='right')\n",
    "\n",
    "# Set labels and title\n",
    "# ax.set_xlabel('Encoded quantity')\n",
    "ax.set_ylabel('Encoding score', fontsize=12)\n",
    "# ax.set_title('Encoding Value by Layer for Each Quantity')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ROOT_DIR, \"data\", \"figures\", \"fig_6\", \"layer_encoding.png\"), format=\"png\", dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myochallenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
