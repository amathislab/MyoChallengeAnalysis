{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of high- and low-variance PCs in velocity space during rotation (panel B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from definitions import ROOT_DIR\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from functions_notebook import make_parallel_envs,set_config,cross_project_kin,plot_cross_projection,mean_ratio\n",
    "import pickle\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from envs.environment_factory import EnvironmentFactory\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_path = os.path.join(ROOT_DIR, \"data\", \"rollouts\", \"final_model_500_episodes_activations_info_small_variations_cw\", \"data.hdf\")\n",
    "rollouts_cw = pd.read_hdf(cw_path)\n",
    "ccw_path = os.path.join(ROOT_DIR, \"data\", \"rollouts\", \"final_model_500_episodes_activations_info_small_variations_ccw\", \"data.hdf\")\n",
    "rollouts_ccw = pd.read_hdf(ccw_path)\n",
    "rollouts_df = pd.concat((rollouts_cw, rollouts_ccw)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_by_timestep(vec, timesteps):\n",
    "    out_vec = []\n",
    "    for ts in sorted(np.unique(timesteps)):\n",
    "        out_vec.append(np.mean(vec[timesteps == ts], axis=0))\n",
    "    return np.vstack(out_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_tangling(data):\n",
    "    derivative = np.gradient(data,axis=0) * 40  # sample frequency\n",
    "\n",
    "    # epsilon = 0.1*np.mean(np.linalg.norm(data,axis=1))\n",
    "    epsilon = 1e-10 # * np.mean(np.linalg.norm(data, axis=1))\n",
    "    # epsilon = 1e-1\n",
    "\n",
    "    Q_all = []\n",
    "    for t in range(derivative.shape[0]):\n",
    "        Q = (np.linalg.norm(derivative[t] - derivative, axis=1)**2) / (epsilon + np.linalg.norm(data[t] - data, axis=1)**2)\n",
    "        Q = np.max(Q)\n",
    "        Q_all.append(Q)\n",
    "    \n",
    "    return np.mean(Q_all)  # as per definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA plots of different component ranges\n",
    "num_muscles = 39\n",
    "num_joints = 23\n",
    "muscle_act = np.vstack(rollouts_df.muscle_act)\n",
    "pos = np.vstack(rollouts_df.observation)[:, :num_joints]\n",
    "\n",
    "pos_pc_range_list = [(0, 3), (5, 8), (12, 15), (20, 23)]\n",
    "muscle_act_pc_range_list = [(0, 3), (23, 26), (36, 39)]\n",
    "cmap_list = [\"Reds\", \"Blues\"]\n",
    "dir_list = [\"cw\", \"ccw\"]\n",
    "label_list = [\"Clockwise\", \"Counter-clockwise\"]\n",
    "data_name_list = [\"joint_pos\", \"muscle_act\"]\n",
    "\n",
    "for data, pc_range_list, data_name in zip([pos, muscle_act], [pos_pc_range_list, muscle_act_pc_range_list], data_name_list):\n",
    "    pca = PCA(n_components=data.shape[1])\n",
    "    out = pca.fit_transform(data)\n",
    "\n",
    "    for pc_range in pc_range_list:\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "        tangling_list = []\n",
    "        for cmap_name, direction, label in zip(cmap_list, dir_list, label_list):\n",
    "            out_direction = out[rollouts_df.task == direction]\n",
    "            cmap = matplotlib.colormaps[cmap_name]\n",
    "            color_list = [cmap(i) for i in np.linspace(0.5, 1, 200)]    \n",
    "            colors = [color_list[idx] for idx in rollouts_df.step[rollouts_df.task == direction]]\n",
    "            plot_mat = out_direction[:, pc_range[0]:pc_range[1]]\n",
    "            # ax.scatter(plot_mat[:, 0], plot_mat[:, 1], plot_mat[:, 2], alpha=0.05, s=0.2, c=colors)\n",
    "            mean_traj = average_by_timestep(plot_mat, rollouts_df.step[rollouts_df.task == direction])\n",
    "            tangling_list.append(measure_tangling(mean_traj))\n",
    "            ax.scatter(mean_traj[:, 0], mean_traj[:, 1], mean_traj[:, 2], c=color_list, label=label)\n",
    "        print(data_name, \"PCs:\", pc_range, \"Tangling:\", np.mean(tangling_list))\n",
    "        # cmap = matplotlib.colormaps[\"Blues\"]\n",
    "        # color_list = [cmap(i) for i in np.linspace(0.3, 1, 200)]    \n",
    "        # colors = [color_list[idx] for idx in rollouts_df.step[rollouts_df.task == \"ccw\"]]\n",
    "        # ax.scatter(out_ccw[:, -3], out_ccw[:, -2], out_ccw[:, -1], alpha=0.05, s=0.2, c=colors)\n",
    "        # mean_traj = average_by_timestep(out_ccw[:, -3:], rollouts_df.step[rollouts_df.task == \"ccw\"])\n",
    "        # ax.scatter(mean_traj[:, 0], mean_traj[:, 1], mean_traj[:, 2], c=color_list)\n",
    "        ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "        ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "        ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "        ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "        ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "        ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "        # ax.set_xlim((-.0025, .0025))\n",
    "        # ax.set_ylim((-.0025, .0025))\n",
    "        # ax.set_zlim((-.003, .003))\n",
    "        # ax.set_title(title + \" - high variance PCs\")\n",
    "        # ax.view_init(25, 45)\n",
    "        ax.view_init(30, 45)\n",
    "        ax.set_xlabel(f\"\\n\\nPC {pc_range[0] + 1}\", fontsize=12)\n",
    "        ax.set_ylabel(f\"\\n\\nPC {pc_range[0] + 2}\", fontsize=12)\n",
    "        ax.set_zlabel(f\"\\n\\nPC {pc_range[0] + 3}\", fontsize=12)\n",
    "        ax.set_box_aspect(aspect=None, zoom=0.7)\n",
    "        ax.ticklabel_format(style=\"sci\", scilimits=(-2, 2))\n",
    "        ax.locator_params(axis='both', nbins=4)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "        # ax.legend()\n",
    "        out_name = f\"pca_{data_name}_components_{'_'.join(str(el) for el in pc_range)}.png\"\n",
    "        fig.savefig(os.path.join(ROOT_DIR, \"data\", \"figures\", \"panel_2\", out_name), format=\"png\", dpi=800, bbox_inches=\"tight\")\n",
    "        fig.show()\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection=\"3d\")\n",
    "# ax.scatter(out[:, -3], out[:, -2], out[:, -1], alpha=0.05, s=1, color=color_by_task)\n",
    "# ax.set_title(title + \" - low variance PCs\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task decoding from the pca trajectories\n",
    "num_muscles = 39\n",
    "num_joints = 23\n",
    "num_episodes_per_direction = 500\n",
    "max_episode_len = 200\n",
    "muscle_act = np.vstack(rollouts_df.muscle_act)\n",
    "pos = np.vstack(rollouts_df.observation)[:, :num_joints]\n",
    "\n",
    "pos_pc_range_list = [(0, 3), (5, 8), (12, 15), (20, 23)]\n",
    "pos_pc_range_span = 3\n",
    "muscle_act_pc_range_list = [(0, 3), (23, 26), (36, 39)]\n",
    "dir_list = [\"cw\", \"ccw\"]\n",
    "data_name_list = [\"joint_pos\", \"muscle_act\"]\n",
    "\n",
    "for data, pc_range_list, data_name in zip([pos, muscle_act], [pos_pc_range_list, muscle_act_pc_range_list], data_name_list):\n",
    "    pca = PCA(n_components=data.shape[1])\n",
    "    out = pca.fit_transform(data)\n",
    "\n",
    "    for pc_range in pc_range_list:\n",
    "        X = np.empty((num_episodes_per_direction * len(dir_list), max_episode_len * pos_pc_range_span))\n",
    "        y = np.empty(num_episodes_per_direction * len(dir_list))\n",
    "        for dir_idx, dir in enumerate(dir_list):\n",
    "            for ep_id in range(num_episodes_per_direction):\n",
    "                step_idx_mask = (rollouts_df.episode == ep_id) & (rollouts_df.task == dir)\n",
    "                row = out[step_idx_mask, pc_range[0]: pc_range[1]].flatten()\n",
    "                X[ep_id + dir_idx * num_episodes_per_direction, : len(row)] = row\n",
    "                y[ep_id + dir_idx * num_episodes_per_direction] = dir_idx\n",
    "        X = X[:, ~np.all(X[1:] == X[:-1], axis=0)]  # drop constant columns\n",
    "        \n",
    "        classification = LogisticRegression()\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_score = cross_val_score(classification, X, y, cv=cv)\n",
    "\n",
    "        print(data_name, \", PC range:\", pc_range, \", score:\", cv_score, \", avg score:\", np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA of the observations\n",
    "# num_muscles = 39\n",
    "# data = np.vstack(rollouts_df.observation)\n",
    "\n",
    "# pca = PCA(n_components=data.shape[1])\n",
    "# out = pca.fit_transform(data)\n",
    "# out_cw = out[tasks == 1]\n",
    "# out_ccw = out[tasks == 0]\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "# cmap = matplotlib.colormaps[\"Reds\"]\n",
    "# color_list = [cmap(i) for i in np.linspace(0.3, 1, 200)]    \n",
    "# colors = [color_list[idx] for idx in rollouts_df.step[rollouts_df.task == \"cw\"]]\n",
    "# ax.scatter(out_cw[:, 0], out_cw[:, 1], out_cw[:, 2], alpha=0.1, s=0.2, c=colors)\n",
    "# mean_traj = average_by_timestep(out_cw[:, :3], rollouts_df.step[rollouts_df.task == \"cw\"])\n",
    "# ax.plot(mean_traj[:, 0], mean_traj[:, 1], mean_traj[:, 2], color=\"r\", linewidth=1)\n",
    "\n",
    "# cmap = matplotlib.colormaps[\"Blues\"]\n",
    "# color_list = [cmap(i) for i in np.linspace(0.3, 1, 200)]    \n",
    "# colors = [color_list[idx] for idx in rollouts_df.step[rollouts_df.task == \"ccw\"]]\n",
    "# ax.scatter(out_ccw[:, 0], out_ccw[:, 1], out_ccw[:, 2], alpha=0.1, s=0.2, c=colors)\n",
    "# mean_traj = average_by_timestep(out_ccw[:, :3], rollouts_df.step[rollouts_df.task == \"ccw\"])\n",
    "# ax.plot(mean_traj[:, 0], mean_traj[:, 1], mean_traj[:, 2], color=\"b\", linewidth=1)\n",
    "# ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "# ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "# ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "# ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "# ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "# ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "# # ax.set_xlim((-0.8, 0.8))\n",
    "# # ax.set_ylim((-.8, .8))\n",
    "# # ax.set_zlim((-.8, .8))\n",
    "# # ax.set_title(title + \" - high variance PCs\")\n",
    "# ax.view_init(25, 47)\n",
    "# ax.set_xlabel(\"PC 1\")\n",
    "# ax.set_ylabel(\"PC 2\")\n",
    "# ax.set_zlabel(\"PC 3\")\n",
    "\n",
    "\n",
    "# fig.savefig(os.path.join(ROOT_DIR, \"data\", \"figures\", \"panel_2\", \"pca_pos_traj_high_variance.png\"), format=\"png\", dpi=600, bbox_inches=\"tight\")\n",
    "# fig.show()\n",
    "\n",
    "# # fig = plt.figure()\n",
    "# # ax = fig.add_subplot(projection=\"3d\")\n",
    "# # ax.scatter(out[:, -3], out[:, -2], out[:, -1], alpha=0.05, s=1, color=color_by_task)\n",
    "# # ax.set_title(title + \" - low variance PCs\")\n",
    "# # fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Low-variance PCs : linear classification performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Go to 2. to directly load the previously-obtained data__\\\n",
    "a. Define the 3 tasks : hold, cw, ccw\\\n",
    "b. Generate and label the velocities for each task\\\n",
    "c. Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ep = 50\n",
    "num_cond = 3\n",
    "\n",
    "PATH_TO_NORMALIZED_ENV = os.path.join(\n",
    "    ROOT_DIR,\n",
    "    \"trained_models/curriculum_steps_complete_baoding_winner/32_phase_2_smaller_rate_resume/env.pkl\",\n",
    ")\n",
    "PATH_TO_PRETRAINED_NET = os.path.join(\n",
    "    ROOT_DIR,\n",
    "    \"trained_models/curriculum_steps_complete_baoding_winner/32_phase_2_smaller_rate_resume/model.zip\",\n",
    ")\n",
    "\n",
    "env_name = \"CustomMyoBaodingBallsP2\"\n",
    "render = False\n",
    "\n",
    "C_hold = set_config(period=1e100,rot_dir=None)\n",
    "C_cw = set_config(period=5,rot_dir=\"cw\")\n",
    "C_ccw = set_config(period=5,rot_dir=\"ccw\")\n",
    "\n",
    "configs = {'hold':C_hold,'cw':C_cw,'ccw':C_ccw}\n",
    "\n",
    "conds = []\n",
    "\n",
    "for task in configs :\n",
    "    envs = make_parallel_envs(env_name, configs[task], num_env=1)\n",
    "    envs = VecNormalize.load(PATH_TO_NORMALIZED_ENV, envs)\n",
    "    envs.training = False\n",
    "    envs.norm_reward = False\n",
    "    custom_objects = {\n",
    "        \"learning_rate\": lambda _: 0,\n",
    "        \"lr_schedule\": lambda _: 0,\n",
    "        \"clip_range\": lambda _: 0,\n",
    "    }\n",
    "    model = RecurrentPPO.load(\n",
    "            PATH_TO_PRETRAINED_NET, env=envs, device=\"cpu\", custom_objects=custom_objects\n",
    "        )\n",
    "\n",
    "    eval_model = model\n",
    "    eval_env = EnvironmentFactory.create(env_name,**configs[task])\n",
    "    tot_vel = []\n",
    "    for n in range(num_ep):\n",
    "        obs_tot = []\n",
    "        cum_reward = 0\n",
    "        lstm_states = None\n",
    "        obs = eval_env.reset()\n",
    "        episode_starts = np.ones((1,), dtype=bool)\n",
    "        done = False\n",
    "        timestep = 0\n",
    "        while not done: \n",
    "            if render :\n",
    "                eval_env.sim.render(mode=\"window\")\n",
    "                \n",
    "            timestep += 1\n",
    "            action, lstm_states = eval_model.predict(envs.normalize_obs(obs),\n",
    "                                                    state=lstm_states,\n",
    "                                                    episode_start=episode_starts,\n",
    "                                                    deterministic=True,\n",
    "                                                    )\n",
    "                                                        \n",
    "            obs, rewards, done, info = eval_env.step(action)\n",
    "            episode_starts = done\n",
    "            cum_reward += rewards\n",
    "            obs_tot.append(obs)\n",
    "        if len(obs_tot) < 200 :\n",
    "            print(\"Stopped before 200, task : %s\" %task, \" number of steps : \",timestep)\n",
    "            temp = np.zeros((200,86))\n",
    "            temp[:len(obs_tot)] += obs_tot\n",
    "            obs_tot = temp\n",
    "        print('episode %s : '%n,cum_reward)\n",
    "\n",
    "        # MEASURE JOINT POSITION AND VELOCITY\n",
    "        hand_positions = np.array(obs_tot)[:,0:23]    \n",
    "        hand_velocities = np.array([np.diff(pos)/0.0025 for pos in hand_positions.T]).T\n",
    "        hand_velocities = np.vstack((np.zeros((1,23)),hand_velocities))                                \n",
    "\n",
    "        conds.append({'task':configs[task],'encoding':task,'reward':cum_reward,'hand velocity':np.array(hand_velocities)})\n",
    "\n",
    "'''fp = \"\"\n",
    "fp_conditions = open(fp, 'wb')\n",
    "pickle.dump(conds,fp_conditions)\n",
    "fp_conditions.close()'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the velocities and labels for each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file from Basecamp : 'synergies_tasks'\n",
    "conds = pickle.load(open(os.path.join(ROOT_DIR, \"data\", \"basecamp\", \"synergies_tasks\"), \"rb\"))\n",
    "hand_kinematics = np.concatenate([cond['hand velocity'] for cond in conds])\n",
    "labels = np.array([cond[\"encoding\"] for cond in conds])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Go to 4. to directly load the classification performance vs. number of high-variance PCs removed__\\\n",
    "a. Compute the PCs\\\n",
    "b. Project the velocities on a progressively lower-dimensional subspace\\\n",
    "c. Train a linear classifier to identify the task's identity (Leave-One-Out cross-validation)\\\n",
    "d. Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 23\n",
    "pca = PCA(n_components=n_comp).fit(hand_kinematics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 0\n",
    "# components = pca.components_[k:, :]\n",
    "# projected_conds = [{'label':cond['encoding'], 'projected velocity':np.dot(cond['hand velocity']+pca.mean_, components)} for cond in conds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_kinematics[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "components = pca.components_[k:, :]\n",
    "coeffs = pca.transform(hand_kinematics)[:, k:]\n",
    "projected_kinematics = np.dot(coeffs, components) + pca.mean_\n",
    "projected_kinematics[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conds[0][\"encoding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_coeffs = pca.transform(hand_kinematics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ep = 50\n",
    "num_cond = 3\n",
    "performance = []\n",
    "for k in range(n_comp):\n",
    "    print(k)\n",
    "    components = pca.components_[k:, :]\n",
    "    projected_conds = []\n",
    "    for cond in conds:\n",
    "        pca_coeffs = np.dot(cond['hand velocity'] - pca.mean_, components.T)\n",
    "        # proj = np.dot(pca_coeffs, components) + pca.mean_\n",
    "        projected_conds.append({'label': cond['encoding'], 'pca_coeffs': pca_coeffs})\n",
    "    \n",
    "    X = [d['projected velocity'].flatten() for d in projected_conds]\n",
    "    y = [d['label'] for d in projected_conds]\n",
    "    class_performance = []\n",
    "    for i in range(num_ep):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X,y,train_size=num_cond*(num_ep-1),test_size=num_cond)\n",
    "        lda = LDA().fit(x_train,y_train)\n",
    "        class_performance.append(lda.score(X=x_test,y=y_test))\n",
    "\n",
    "    performance.append(np.mean(np.array(class_performance)))\n",
    " \n",
    "'''fp = \"\"    \n",
    "fp_perf = open(fp, 'wb')\n",
    "pickle.dump(performance,fp_perf)\n",
    "fp.close()'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load the classification performance vs. number of high-variance PCs removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file from basecamp : 'class_performance_tasks_r'\n",
    "performance = pickle.load(open(os.path.join(ROOT_DIR, \"data\", \"basecamp\", \"class_performance_tasks_r\"), \"rb\"))\n",
    "n_comp=23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Plot the classification performance vs. number of high-variance PCs removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_low_variance = next(x[0] for x in enumerate(pca.explained_variance_ratio_) if x[1] < 0.01)\n",
    "plt.plot([n for n in range(n_comp)],performance,'-o',linewidth=1,markersize=2,color='black')\n",
    "plt.axvline(x=pc_low_variance, ymax=0.46,color='r', linestyle='-',linewidth=1,label='1% Variance')\n",
    "plt.legend(fontsize=21)\n",
    "plt.xlabel('Number of PCs removed',fontsize=21)\n",
    "plt.ylabel('Accuracy',fontsize=21)\n",
    "plt.title('Classification performance',fontsize=21)\n",
    "plt.yticks(fontsize=21)\n",
    "plt.xticks(fontsize=21)\n",
    "plt.subplots_adjust(left=0.21,bottom=0.15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. High-variance PCs : cross-projection similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the velocities and labels for each task (same as in section A.2.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file from basecamp : 'synergies_tasks'\n",
    "conds = pickle.load(open('/home/ingster/Bureau/SIL-BigResults/synergies_tasks','rb')) \n",
    "\n",
    "hold_velocities = np.concatenate([cond['hand velocity'] for cond in conds if cond['encoding']=='hold'])\n",
    "cw_velocities = np.concatenate([cond['hand velocity'] for cond in conds if cond['encoding']=='cw'])\n",
    "ccw_velocities = np.concatenate([cond['hand velocity'] for cond in conds if cond['encoding']=='ccw'])\n",
    "\n",
    "n_comp = 23\n",
    "n_highpc = 12 # Considering that the first 12 PCs account for most of the variance = high-variance PCs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. a. Cross-projection \\\n",
    "b. Quantify the degree of similarity between subpaces by computing average V2/V1\\\n",
    "c. Visualize the degree of similarity between subspaces by plotting cumulative explained variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-projection\n",
    "cproj_hold_cw = cross_project_kin(vel1=hold_velocities,vel2=ccw_velocities,n_comp=n_comp,n_highpc=n_highpc)\n",
    "cproj_hold_ccw = cross_project_kin(vel1=hold_velocities,vel2=ccw_velocities,n_comp=n_comp,n_highpc=n_highpc)\n",
    "cproj_ccw_cw = cross_project_kin(vel1=ccw_velocities,vel2=cw_velocities,n_comp=n_comp,n_highpc=n_highpc)\n",
    "\n",
    "# Quantify\n",
    "hold_cw = mean_ratio(n_highpc=n_highpc,cproj=cproj_hold_cw)\n",
    "hold_ccw = mean_ratio(n_highpc=n_highpc,cproj=cproj_hold_ccw)\n",
    "ccw_cw = mean_ratio(n_highpc=n_highpc,cproj=cproj_ccw_cw)\n",
    "\n",
    "hold_cw_r = hold_cw[0]\n",
    "hold_ccw_r = hold_ccw[0]\n",
    "ccw_cw_r = ccw_cw[0]\n",
    "\n",
    "V = {'hold vs. cw':np.round(hold_cw_r,7), 'hold vs. ccw':np.round(hold_ccw_r,7), 'cw vs. ccw':np.round(ccw_cw_r,7)}\n",
    "print(V)\n",
    "\n",
    "# Visualize\n",
    "plot_cross_projection(n_comp=n_comp,cum_1_2=hold_cw[1],cum_2_1=hold_cw[2],label1='Hold on CW',label2='CW on hold')\n",
    "plot_cross_projection(n_comp=n_comp,cum_1_2=hold_ccw[1],cum_2_1=hold_ccw[2],label1='Hold on CCW',label2='CCW on hold')\n",
    "plot_cross_projection(n_comp=n_comp,cum_1_2=ccw_cw[1],cum_2_1=ccw_cw[2],label1='CCW on CW',label2='CW on CCW')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
