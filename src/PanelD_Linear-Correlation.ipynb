{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear correlation of non-explicitely encoded variables with observations and LSTM output (panel D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from definitions import ROOT_DIR\n",
    "import sklearn.linear_model\n",
    "from envs.environment_factory import EnvironmentFactory\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from functions_notebook import make_parallel_envs\n",
    "from matplotlib.cm import get_cmap\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset and run linear regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_hdf(os.path.join(ROOT_DIR, \"data\", \"rollouts\", \"final_model_500_episodes_activations_info_ccw\", \"data.hdf\"))\n",
    "df2 = pd.read_hdf(os.path.join(ROOT_DIR, \"data\", \"rollouts\", \"final_model_500_episodes_activations_info_cw\", \"data.hdf\"))\n",
    "\n",
    "df = pd.concat((df1, df2)).reset_index()\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "regression = sklearn.linear_model.LinearRegression()\n",
    "for target in [\"mass_1\", \"mass_2\", \"size_1\", \"size_2\", \"friction_0\", \"friction_1\", \"friction_2\", \"x_radius\", \"y_radius\"]:\n",
    "    for key in [\"observation\", \"lstm_state_0\", \"lstm_state_1\", \"lstm_out\", \"layer_1_out\", \"layer_2_out\", \"action\"]:\n",
    "        X = np.array(df[key].to_list())\n",
    "        y = df[target].to_numpy()\n",
    "        cv = sklearn.model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        # lin_model = regression.fit(X, y)\n",
    "        # score = regression.score(X, y)\n",
    "        cv_score = sklearn.model_selection.cross_val_score(regression, X, y, cv=cv)\n",
    "        print(\"Key:\", key, \" target:\", target,  \"score:\", cv_score)\n",
    "        results_list.append({\"input\": key, \"target\": target, \"score\": cv_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = sklearn.linear_model.LogisticRegression(max_iter=10_000)\n",
    "target = \"task\"\n",
    "for key in [\"observation\", \"lstm_state_0\", \"lstm_state_1\", \"lstm_out\", \"layer_1_out\", \"layer_2_out\", \"action\"]:\n",
    "    X = np.array(df[key].to_list())\n",
    "    y = df[target].to_numpy()\n",
    "    cv = sklearn.model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_score = sklearn.model_selection.cross_val_score(classification, X, y, cv=cv)\n",
    "    print(\"Key:\", key, \" target:\", target,  \"score:\", cv_score)\n",
    "    results_list.append({\"input\": key, \"target\": target, \"score\": cv_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = sklearn.linear_model.LinearRegression()\n",
    "for target in [\"hand_pos\", \"hand_vel\"]:\n",
    "    for key in [\"observation\", \"lstm_state_0\", \"lstm_state_1\", \"lstm_out\", \"layer_1_out\", \"layer_2_out\", \"action\"]:\n",
    "        X = np.array(df[key].to_list())\n",
    "        y = np.array(df[target].to_list())\n",
    "\n",
    "        cv = sklearn.model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_score = sklearn.model_selection.cross_val_score(regression, X, y, cv=cv)\n",
    "\n",
    "        print(\"Key:\", key, \" target:\", target,  \"score:\", cv_score)\n",
    "        results_list.append({\"input\": key, \"target\": target, \"score\": cv_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list_mean_sem = [{\n",
    "    \"input\": el[\"input\"],\n",
    "    \"target\": el[\"target\"],\n",
    "    \"score_mean\": np.mean(el[\"score\"]),\n",
    "    \"score_std\": np.std(el[\"score\"])\n",
    "    }\n",
    "    for el in results_list\n",
    "]\n",
    "results_df = pd.DataFrame(results_list_mean_sem)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_list = [\"observation\", \"lstm_state_1\", \"lstm_out\", \"layer_1_out\", \"layer_2_out\", \"action\"]\n",
    "layers_name_list = [\"Observation\", \"LSTM state\", \"LSTM out\", \"Layer 1 out\", \"Layer 2 out\", \"Action\"]\n",
    "targets_list = [\"mass_1\", \"mass_2\", \"size_1\", \"size_2\", \"friction_0\", \"friction_1\", \"friction_2\", \"x_radius\", \"y_radius\", \"task\", \"hand_pos\", \"hand_vel\"]\n",
    "targets_name_list = [\"Mass 1\", \"Mass 2\", \"Size 1\", \"Size 2\", \"Friction 0\", \"Friction 1\", \"Friction 2\", \"Radius x\", \"Radius y\", \"Task\", \"Joint pos\", \"Joint vel\"]\n",
    "\n",
    "# Create a colormap with distinct colors\n",
    "num_value_types = len(set([value.split(\"_\")[0] for value in targets_list]))\n",
    "cmap = plt.get_cmap('brg')\n",
    "colors = [cmap(i % num_value_types) for i in range(len(targets_list))]\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for target, target_name, c in zip(targets_list, targets_name_list, colors):\n",
    "    score_list = []\n",
    "    for layer in layers_list:\n",
    "        score = results_df[(results_df.input == layer) & (results_df.target == target)].score_mean.item()\n",
    "        score_list.append(score)\n",
    "    score_vec = np.array(score_list) / max(score_list)\n",
    "    ax.plot(score_vec, label=target_name, color=c)\n",
    "ax.legend()\n",
    "ax.set_xticks(range(6), labels=layers_name_list, rotation=30)\n",
    "ax.set_ylabel(\"Rescaled score\")\n",
    "ax.legend(bbox_to_anchor=(1, 1))\n",
    "plt.savefig(os.path.join(ROOT_DIR, \"data\", \"figures\", \"panel_4\", \"layer_encoding.png\"), format=\"png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_list = [\"observation\", \"lstm_state_1\", \"lstm_out\", \"layer_1_out\", \"layer_2_out\", \"action\"]\n",
    "layers_name_list = [\"Observation\", \"LSTM state\", \"LSTM out\", \"Layer 1 out\", \"Layer 2 out\", \"Action\"]\n",
    "targets_list = [\"mass_1\", \"mass_2\", \"size_1\", \"size_2\", \"friction_0\", \"friction_1\", \"friction_2\", \"x_radius\", \"y_radius\", \"task\", \"hand_pos\", \"hand_vel\"]\n",
    "targets_name_list = [\"Mass 1\", \"Mass 2\", \"Size 1\", \"Size 2\", \"Friction 0\", \"Friction 1\", \"Friction 2\", \"Radius x\", \"Radius y\", \"Task\", \"Joint pos\", \"Joint vel\"]\n",
    "\n",
    "# Create a colormap with distinct colors\n",
    "num_value_types = len(set([value.split(\"_\")[0] for value in targets_list]))\n",
    "cmap = plt.get_cmap('tab20')\n",
    "colors = [cmap(i % num_value_types) for i in range(len(targets_list))]\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for target, target_name, c in zip(targets_list, targets_name_list, colors):\n",
    "    score_list = []\n",
    "    for layer in layers_list:\n",
    "        score = results_df[(results_df.input == layer) & (results_df.target == target)].score_mean.item()\n",
    "        score_list.append(score)\n",
    "    score_vec = np.array(score_list) / max(score_list)\n",
    "    ax.plot(score_vec, label=target_name, color=c)\n",
    "ax.legend()\n",
    "ax.set_xticks(range(6), labels=layers_name_list, rotation=30)\n",
    "ax.set_ylabel(\"Rescaled score\")\n",
    "ax.legend(bbox_to_anchor=(1, 1))\n",
    "plt.savefig(os.path.join(ROOT_DIR, \"data\", \"figures\", \"panel_4\", \"layer_encoding.png\"), format=\"png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_list = [\"observation\", \"lstm_state_1\", \"lstm_out\", \"layer_1_out\", \"layer_2_out\", \"action\"]\n",
    "layers_name_list = [\"Observation\", \"Memory\", \"LSTM output\", \"Layer 1\", \"Layer 2\", \"Action\"]\n",
    "targets_list = [\"mass_1\", \"mass_2\", \"size_1\", \"size_2\", \"friction_0\", \"friction_1\", \"friction_2\", \"x_radius\", \"y_radius\", \"task\", \"hand_pos\", \"hand_vel\"]\n",
    "targets_name_list = [\"Mass 1\", \"Mass 2\", \"Size 1\", \"Size 2\", \"Friction 0\", \"Friction 1\", \"Friction 2\", \"Radius x\", \"Radius y\", \"Task\", \"Joint pos\", \"Joint vel\"]\n",
    "\n",
    "# Create a pivot table to reshape the data\n",
    "pivot_data = results_df.pivot(index=\"target\", columns=\"input\", values=\"score_mean\").loc[targets_list]\n",
    "pivot_std = results_df.pivot(index=\"target\", columns=\"input\", values=\"score_std\").loc[targets_list]\n",
    "\n",
    "# Set the width of each bar\n",
    "bar_width = 0.15\n",
    "\n",
    "# Create an array of x values for the bars\n",
    "x = np.arange(len(targets_list))\n",
    "\n",
    "# Create a grouped barplot\n",
    "fig, ax = plt.subplots(figsize=(5, 3.5))\n",
    "cmap = get_cmap(\"coolwarm\")\n",
    "\n",
    "\n",
    "for i, layer in enumerate(layers_list):\n",
    "    ax.bar(x + i * bar_width, pivot_data[layer], bar_width, yerr=pivot_std[layer], label=layers_name_list[i], color=cmap((i) / (len(layers_list))), alpha=0.9)\n",
    "\n",
    "# Set x-axis labels and tick positions\n",
    "ax.set_xticks(x + (len(pivot_data.columns) / 2) * bar_width)\n",
    "ax.set_xticklabels(targets_name_list, rotation=45, ha='right')\n",
    "\n",
    "# Set labels and title\n",
    "# ax.set_xlabel('Encoded quantity')\n",
    "ax.set_ylabel('Encoding score', fontsize=12)\n",
    "# ax.set_title('Encoding Value by Layer for Each Quantity')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ROOT_DIR, \"data\", \"figures\", \"panel_4\", \"layer_encoding_barplot.png\"), format=\"png\", dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Record the observations and LSTM outputs together with hand's velocity and acceleration, ball mass, size and friction, and trajectory radius. __Go to 2. to directly load the previously-obtained data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_NORMALIZED_ENV = os.path.join(\n",
    "    ROOT_DIR,\n",
    "    \"trained_models/curriculum_steps_complete_baoding_winner/32_phase_2_smaller_rate_resume/env.pkl\",\n",
    ")\n",
    "PATH_TO_PRETRAINED_NET = os.path.join(\n",
    "    ROOT_DIR,\n",
    "    \"trained_models/curriculum_steps_complete_baoding_winner/32_phase_2_smaller_rate_resume/model.zip\",\n",
    ")\n",
    "\n",
    "config = {\n",
    "\"weighted_reward_keys\": {\n",
    "    \"pos_dist_1\": 0,\n",
    "    \"pos_dist_2\": 0,\n",
    "    \"act_reg\": 0,\n",
    "    \"alive\": 0,\n",
    "    \"solved\": 5,\n",
    "    \"done\": 0,\n",
    "    \"sparse\": 0\n",
    "},\n",
    "\"enable_rsi\": False,\n",
    "\"rsi_probability\": 0,\n",
    "\"balls_overlap\": False,\n",
    "\"overlap_probability\": 0,\n",
    "\"noise_fingers\": 0,\n",
    "\"limit_init_angle\": 0,\n",
    "\"goal_time_period\": [\n",
    "    4,\n",
    "    6\n",
    "],\n",
    "\"goal_xrange\": [\n",
    "    0.02,\n",
    "    0.03\n",
    "],\n",
    "\"goal_yrange\": [\n",
    "    0.022,\n",
    "    0.032\n",
    "],\n",
    "\"obj_size_range\": [\n",
    "    0.018,\n",
    "    0.021\n",
    "],\n",
    "\"obj_mass_range\": [\n",
    "    0.03,\n",
    "    0.3\n",
    "],\n",
    "\"obj_friction_change\": [\n",
    "    0.2,\n",
    "    0.001,\n",
    "    2e-05\n",
    "],\n",
    "\"task_choice\": \"random\"\n",
    "}\n",
    "\n",
    "env_name = 'CustomMyoBaodingBallsP2'\n",
    "render = False\n",
    "\n",
    "envs = make_parallel_envs(env_name, config, num_env=1)\n",
    "envs = VecNormalize.load(PATH_TO_NORMALIZED_ENV, envs)\n",
    "envs.training = False\n",
    "envs.norm_reward = False\n",
    "custom_objects = {\n",
    "    \"learning_rate\": lambda _: 0,\n",
    "    \"lr_schedule\": lambda _: 0,\n",
    "    \"clip_range\": lambda _: 0,\n",
    "}\n",
    "model = RecurrentPPO.load(\n",
    "    PATH_TO_PRETRAINED_NET, env=envs, device=\"cpu\", custom_objects=custom_objects\n",
    ")\n",
    "\n",
    "# EVALUATE\n",
    "eval_model = model\n",
    "eval_env = EnvironmentFactory.create(env_name, **config)   \n",
    "\n",
    "num_episodes = 500\n",
    "\n",
    "data_list = []\n",
    "for n in range(num_episodes) :\n",
    "    lstm_states = (np.zeros((1, 1, 256)), np.zeros((1, 1, 256)))\n",
    "    cum_rew = 0\n",
    "    step = 0\n",
    "    obs = eval_env.reset()\n",
    "    episode_starts = torch.ones((1,))\n",
    "    done = False\n",
    "    while not done:\n",
    "        lstm_states_tensor = (torch.tensor(lstm_states[0], dtype=torch.float32).reshape(1, -1), torch.tensor(lstm_states[1], dtype=torch.float32).reshape(1, -1))     \n",
    "        action, lstm_states = eval_model.predict(\n",
    "            envs.normalize_obs(obs),\n",
    "            state=lstm_states,\n",
    "            episode_start=episode_starts,\n",
    "            deterministic=True,\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            features = eval_model.policy.extract_features(torch.tensor(envs.normalize_obs(obs)).reshape(1, -1))\n",
    "            lstm_out, _ = eval_model.policy.lstm_actor(features, (lstm_states_tensor[0] * (1 - episode_starts), lstm_states_tensor[1] * (1 - episode_starts)))\n",
    "            layer_1_out = eval_model.policy.mlp_extractor.policy_net[1](eval_model.policy.mlp_extractor.policy_net[0](lstm_out))\n",
    "            layer_2_out = eval_model.policy.mlp_extractor.policy_net[3](eval_model.policy.mlp_extractor.policy_net[2](layer_1_out))\n",
    "            action_pred = eval_model.policy._get_action_dist_from_latent(layer_2_out).mode().clip(-1, 1)\n",
    "\n",
    "        assert np.allclose(action_pred, action), print(action_pred, action)\n",
    "        next_obs, rewards, done, info = eval_env.step(action)\n",
    "        episode_starts = done\n",
    "        cum_rew += rewards\n",
    "        step += 1\n",
    "\n",
    "        hand_pos = obs[0:23]\n",
    "        hand_vel = (next_obs[0:23] - hand_pos) / 0.0025\n",
    "        \n",
    "        data_point = {\n",
    "            'episode' : n, \n",
    "            'time step': step,\n",
    "            'observation': envs.normalize_obs(obs),\n",
    "            \"lstm_state_0\": np.squeeze(lstm_states[0]),\n",
    "            \"lstm_state_1\": np.squeeze(lstm_states[1]),\n",
    "            \"lstm_out\": np.squeeze(lstm_out.numpy()),\n",
    "            \"layer_1_out\": np.squeeze(layer_1_out.numpy()),\n",
    "            \"layer_2_out\": np.squeeze(layer_2_out.numpy()),\n",
    "            \"action\": action,\n",
    "            \"mass_1\": eval_env.sim.model.body_mass[eval_env.object1_bid],\n",
    "            \"size_1\": eval_env.sim.model.geom_size[eval_env.object1_gid][0],\n",
    "            \"mass_2\": eval_env.sim.model.body_mass[eval_env.object2_bid],\n",
    "            \"size_2\": eval_env.sim.model.geom_size[eval_env.object2_gid][0],\n",
    "            \"friction_0\": eval_env.sim.model.geom_friction[eval_env.object1_gid][0],\n",
    "            \"friction_1\": eval_env.sim.model.geom_friction[eval_env.object1_gid][1],\n",
    "            \"friction_2\": eval_env.sim.model.geom_friction[eval_env.object1_gid][2],\n",
    "            \"x_radius\": eval_env.x_radius,\n",
    "            \"y_radius\": eval_env.y_radius,\n",
    "            \"task\": eval_env.which_task.value,\n",
    "            \"hand_pos\": hand_pos,\n",
    "            \"hand_vel\": hand_vel\n",
    "        }\n",
    "        data_list.append(data_point)\n",
    "        obs = next_obs\n",
    "    print(\"Reward:\", cum_rew, \"length:\", step) \n",
    "        \n",
    "df = pd.DataFrame(data_list)\n",
    "df.to_hdf(os.path.join(ROOT_DIR, \"data\", \"basecamp\", \"activation_df.hdf\"), key=\"activations\")            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the file from Basecamp : 'lin_corr'\n",
    "# params = pickle.load(open(os.path.join(ROOT_DIR, \"data\", \"basecamp\", \"lin_corr\"),'rb'))\n",
    "\n",
    "# M=params['Mass']\n",
    "# Ra=params['Radius']\n",
    "# Fr=params['Friction']\n",
    "# S=params['Size']\n",
    "# VEL=params['Velocity']\n",
    "# ACC=params['Acceleration']\n",
    "# OBS=params['Observations']\n",
    "# LSTM=params['LSTM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Go to 4. to directly access the previously-obtained data.__\\\n",
    "a. Compute the linear regression and the associated coefficient of determination\\\n",
    "b. Save the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# R_lstm = {'hand velocity':None,'hand acceleration':None,'mass':None,'size':None,'friction':None,'radius':None}\n",
    "# R_obs = {'hand velocity':None,'hand acceleration':None,'mass':None,'size':None,'friction':None,'radius':None}\n",
    "\n",
    "# layers = [OBS,LSTM]\n",
    "# R = [R_obs,R_lstm]\n",
    "\n",
    "# for i in range(len(R)):\n",
    "\n",
    "#     lin_model = regression.fit(y=VEL,X=layers[i])\n",
    "#     R[i]['hand velocity'] = np.round(lin_model.score(y=VEL,X=layers[i]),5)\n",
    "\n",
    "#     lin_model = regression.fit(y=ACC,X=layers[i])\n",
    "#     R[i]['hand acceleration'] = np.round(lin_model.score(y=ACC,X=layers[i]),5)\n",
    "\n",
    "#     lin_model = regression.fit(y=M,X=layers[i])\n",
    "#     R[i]['mass'] = np.round(lin_model.score(X=layers[i],y=M),5)\n",
    "\n",
    "#     lin_model = regression.fit(y=S,X=layers[i])\n",
    "#     R[i]['size'] = np.round(lin_model.score(y=S,X=layers[i]),5)\n",
    "\n",
    "#     lin_model = regression.fit(y=Fr,X=layers[i])\n",
    "#     R[i]['friction'] = np.round(lin_model.score(y=Fr,X=layers[i]),5)\n",
    "\n",
    "#     lin_model = regression.fit(y=Ra,X=layers[i])\n",
    "#     R[i]['radius'] = np.round(lin_model.score(y=Ra,X=layers[i]),5)\n",
    "\n",
    "# for R_layer in R : \n",
    "#     print(R_layer)\n",
    "\n",
    "# fp = \".csv\"\n",
    "# pd.DataFrame(R).to_csv(os.path.join(ROOT_DIR,fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load the previously-obtained R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the file from Basecamp : 'v2_32_phase_2_smaller_rate_resume.csv'\n",
    "# R = pd.read_csv(os.path.join(ROOT_DIR,\"SIL-Results/Linear-correlation/v2_32_phase_2_smaller_rate_resume.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(os.path.join(ROOT_DIR, \"data\", \"basecamp\", \"activation_df.hdf\"))\n",
    "df.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyoChallenge2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
